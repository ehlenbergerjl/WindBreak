{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Jason's to-do list:\n",
    "- April-June 2014, 2016, 2018\n",
    "- Histogram to understand the distribution of the data\n",
    "- Summary Table\n",
    "    - Ways to summarize the hourly wind data: \n",
    "        - Mean wind speed for a county in a given month  \n",
    "        - Max wind speed for a county in a given month \n",
    "        - Number of times we had high wind speed (15+ m2/sec) \n",
    "- ArcPro Map -- Spatial map of which places receive the most wind events and when?\n",
    "\n",
    "[Project Guidelines](https://docs.google.com/document/d/13_CxrlfxYHFuPd_BJ2xTrvWDS41ie3TAWVYSBK8_nhU/edit?pli=1)\n",
    "\n",
    "Spatial and temporal analysis of the wind speed and wind event data and its relationship with crop loss (COL data):\n",
    "- Since we know that crop loss is directly proportional to wind speed, we will try to explore the relationship here. \n",
    "    - What types of wind variables have high correlation with crop loss? \n",
    "    - Is it maximum wind speed, number of high wind speed events in a given month, or something else? \n",
    "- By overlaying the wind speed over the crop cover data (raster data), we can see which crops these high wind events generally damage and when?\n",
    "- Since crop loss data is available at a monthly time-scale at county level, we need to aggregate the wind data at the county level. \n",
    "- What kind of aggregation would you need to do to explore its relationship with crop loss? E.g. (just thoughts) the number of medium vs high wind events in a month for a particular county, the number of tornadoes in the county, etc. \n",
    "\n",
    "April red hex E41A1C\n",
    "May blue hex 377EB8\n",
    "June green hex 4DAF4A\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f08c0c81f1b8a21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting started\n",
    "Intstall the latest [MiniConda](https://docs.anaconda.com/free/miniconda/) for your Operating System \n",
    "- When asked, I recommend you install for 'Just me', not 'All users'\n",
    "- This is important if you are not admin on your system\n",
    "\n",
    "Create your environment in a Python shell (Terminal in PyCharm)\n",
    "- Replace 'myenv' with whatever name you want to give your new environment\n",
    "- I'm calling mine 'WindBreaks'\n",
    "Install these packages with the '--yes' option to keep it moving without asking questions \n",
    "- ... or you can leave that out if you want to know what is being upgraded/downgraded/installed for compatibility and dependency\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "    # Create new env\n",
    "    conda create --name myenv\n",
    "    # Activate new env \n",
    "    conda activate myenv\n",
    "    # Install the packages\n",
    "    python -m pip install jupyter\n",
    "    conda install -c anaconda ipykernel --yes\n",
    "    conda install -c conda-forge IPython --yes\n",
    "    conda install -c conda-forge netCDF4 --yes\n",
    "    conda install -c conda-forge rasterio --yes\n",
    "    conda install -c conda-forge numpy --yes\n",
    "    conda install -c conda-forge xarray --yes\n",
    "    conda install -c pyviz hvplot --yes\n",
    "    conda install -c conda-forge holoviews --yes\n",
    "    conda install -c anaconda pandas --yes\n",
    "    conda install -c anaconda seaborn --yes\n",
    "    conda install -c conda-forge matplotlib --yes\n",
    "    conda install -c anaconda regex --yes\n",
    "    conda install -c conda-forge cartopy --yes\n",
    "    conda install -c conda-forge ipywidgets --yes\n",
    "\n",
    "    # Create the Jupyter Kernal for your notebook\n",
    "    python -m ipykernel install --user --name WindBreaks --display-name \"WindBreaks\"\n",
    "\n",
    "    \n",
    "## Possible additional resources:\n",
    "### Tutorials\n",
    "   #### Exploratory Analysis\n",
    "   - [Tutorial 1](https://www.geeksforgeeks.org/quick-guide-to-exploratory-data-analysis-using-jupyter-notebook/)\n",
    "   - [YOUR Data Teacher (YouTube video)](https://www.youtube.com/watch?v=iZ2MwVWKwr4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c458e13e7c1e40f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Sources\n",
    "[NOAA Local Climate Data (LCD)](https://www.ncei.noaa.gov/maps/lcd/)\n",
    "[NOAA Storm Events (NCEI)](https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/)\n",
    "[Copernicus Climate Data Store (CDS)](https://cds.climate.copernicus.eu/cdsapp#!/home)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc7323bb4c25e55a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T18:37:06.459749Z",
     "start_time": "2024-03-28T18:37:06.452534Z"
    }
   },
   "id": "fc95b71945dc61b1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.0.min.js\", \"https://cdn.holoviz.org/panel/1.4.0/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.0'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.0.min.js\", \"https://cdn.holoviz.org/panel/1.4.0/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<style>*[data-root-id],\n*[data-root-id] > * {\n  box-sizing: border-box;\n  font-family: var(--jp-ui-font-family);\n  font-size: var(--jp-ui-font-size1);\n  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n}\n\n/* Override VSCode background color */\n.cell-output-ipywidget-background:has(\n    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n  ),\n.cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n  background-color: transparent !important;\n}\n</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div id='p1002'>\n  <div id=\"cc997627-34fb-4137-bb7b-5c314906c27a\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n</div>\n<script type=\"application/javascript\">(function(root) {\n  var docs_json = {\"94c28983-c9b7-4240-b754-e9a4fb7aaaf5\":{\"version\":\"3.4.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"79557e682583400dbb4cf1d90a6cddd0\",\"client_comm_id\":\"67002ff731da4c82ad1af70b7fc7f674\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n  var render_items = [{\"docid\":\"94c28983-c9b7-4240-b754-e9a4fb7aaaf5\",\"roots\":{\"p1002\":\"cc997627-34fb-4137-bb7b-5c314906c27a\"},\"root_ids\":[\"p1002\"]}];\n  var docs = Object.values(docs_json)\n  if (!docs) {\n    return\n  }\n  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n  function embed_document(root) {\n    var Bokeh = get_bokeh(root)\n    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n    for (const render_item of render_items) {\n      for (const root_id of render_item.root_ids) {\n\tconst id_el = document.getElementById(root_id)\n\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n\t  const root_el = id_el.children[0]\n\t  root_el.id = root_el.id + '-rendered'\n\t}\n      }\n    }\n  }\n  function get_bokeh(root) {\n    if (root.Bokeh === undefined) {\n      return null\n    } else if (root.Bokeh.version !== py_version) {\n      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n\treturn null\n      }\n      return root.Bokeh.versions.get(py_version);\n    } else if (root.Bokeh.version === py_version) {\n      return root.Bokeh\n    }\n    return null\n  }\n  function is_loaded(root) {\n    var Bokeh = get_bokeh(root)\n    return (Bokeh != null && Bokeh.Panel !== undefined)\n  }\n  if (is_loaded(root)) {\n    embed_document(root);\n  } else {\n    var attempts = 0;\n    var timer = setInterval(function(root) {\n      if (is_loaded(root)) {\n        clearInterval(timer);\n        embed_document(root);\n      } else if (document.readyState == \"complete\") {\n        attempts++;\n        if (attempts > 200) {\n          clearInterval(timer);\n\t  var Bokeh = get_bokeh(root)\n\t  if (Bokeh == null || Bokeh.Panel == null) {\n            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n\t  } else {\n\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n\t    embed_document(root)\n\t  }\n        }\n      }\n    }, 25, root)\n  }\n})(window);</script>",
      "application/vnd.holoviews_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _imaging: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mholoviews\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mhv\u001B[39;00m \n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgeopandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgpd\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\conda\\envs\\WindBreaks\\Lib\\site-packages\\seaborn\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Import seaborn objects\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrcmod\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401,F403\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401,F403\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpalettes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F401,F403\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\conda\\envs\\WindBreaks\\Lib\\site-packages\\seaborn\\rcmod.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"Control plot style and scaling using the matplotlib rcParams interface.\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mfunctools\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcycler\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cycler\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m palettes\n",
      "File \u001B[1;32m~\\AppData\\Local\\conda\\envs\\WindBreaks\\Lib\\site-packages\\matplotlib\\__init__.py:161\u001B[0m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse \u001B[38;5;28;01mas\u001B[39;00m parse_version\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# cbook must import matplotlib only within function\u001B[39;00m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# definitions, so it is safe to import from it here.\u001B[39;00m\n\u001B[1;32m--> 161\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sanitize_sequence\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MatplotlibDeprecationWarning\n",
      "File \u001B[1;32m~\\AppData\\Local\\conda\\envs\\WindBreaks\\Lib\\site-packages\\matplotlib\\rcsetup.py:27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, cbook\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ls_mapper\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Colormap, is_color_like\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_fontconfig_pattern\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_fontconfig_pattern\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_enums\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m JoinStyle, CapStyle\n",
      "File \u001B[1;32m~\\AppData\\Local\\conda\\envs\\WindBreaks\\Lib\\site-packages\\matplotlib\\colors.py:52\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumbers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Real\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n\u001B[1;32m---> 52\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mPngImagePlugin\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PngInfo\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\conda\\envs\\WindBreaks\\Lib\\site-packages\\PIL\\Image.py:84\u001B[0m\n\u001B[0;32m     75\u001B[0m MAX_IMAGE_PIXELS \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001B[39;00m\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001B[39;00m\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;66;03m# import Image and use the Image.core variable instead.\u001B[39;00m\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001B[39;00m\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;66;03m# and should be considered private and subject to change.\u001B[39;00m\n\u001B[1;32m---> 84\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _imaging \u001B[38;5;28;01mas\u001B[39;00m core\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m __version__ \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(core, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPILLOW_VERSION\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     87\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     88\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     89\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCore version: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mgetattr\u001B[39m(core,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPILLOW_VERSION\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     90\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPillow version: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     91\u001B[0m         )\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing _imaging: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import regex as re\n",
    "import netCDF4 as nc\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import holoviews as hv \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.ticker as mticker"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T18:37:18.936767Z",
     "start_time": "2024-03-28T18:37:07.132325Z"
    }
   },
   "id": "734e8a966804eacb",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.resources import INLINE\n",
    "from rasterio.transform import from_origin\n",
    "from rasterstats import zonal_stats\n",
    "from shapely.geometry import LineString\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.colors import Normalize\n",
    "from netCDF4 import Dataset\n",
    "from IPython.display import display\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T18:37:18.944932Z",
     "start_time": "2024-03-28T18:37:18.944932Z"
    }
   },
   "id": "9bda9e537b38cd67",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set up Bokeh to display plots inline in the notebook.\n",
    "output_notebook(INLINE)\n",
    "hv.extension('bokeh')\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-28T18:37:18.947922Z"
    }
   },
   "id": "be92c728dd565a1d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Path to the directory\n",
    "directory = 'Data'\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.isdir(directory):\n",
    "    src_dir = directory\n",
    "else:\n",
    "    src_dir = None\n",
    "\n",
    "print(src_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac774d0c0fd0ea3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "whos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b7e2ff848f935e2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extent Filter Function that works with the variable 'extents_coords'\n",
    "def filter_dataframe_on_extent(df, extent_coords, lat1, lon1, lat2, lon2):\n",
    "    min_lat, max_lat = extent_coords['min_lat'], extent_coords['max_lat']\n",
    "    min_lon, max_lon = extent_coords['min_lon'], extent_coords['max_lon']\n",
    "    return df[\n",
    "        ((df[lat1] >= min_lat) & (df[lat1] <= max_lat) &\n",
    "         (df[lon1] >= min_lon) & (df[lon1] <= max_lon)) |\n",
    "        ((df[lat2] >= min_lat) & (df[lat2] <= max_lat) &\n",
    "         (df[lon2] >= min_lon) & (df[lon2] <= max_lon))\n",
    "        ]\n",
    "\n",
    "\n",
    "# Project extents\n",
    "extent_coords = {'min_lat': 36.998665, 'max_lat': 37.734463,\n",
    "                 'min_lon': -95.964735, 'max_lon': -94.616789}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47f39387e6fe36fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the county boundary shapefile\n",
    "sixco_fn = os.path.join(src_dir, 'GIS_files/KS_six_co_bo.shp')\n",
    "data = gpd.read_file(sixco_fn)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9531a2279283a20e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the Storm event data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96bba2f8dad613d0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # import matplotlib.pyplot as plt\n",
    "# # import cartopy.crs as ccrs\n",
    "# # import cartopy.feature as cf\n",
    "# # import numpy as np\n",
    "# # from netCDF4 import Dataset\n",
    "# \n",
    "# def ncplotter(mrc, file: str, dep_var: str, width=6, height=6,\n",
    "#               ax_title=\"Colorbar\", plt_title=\"Plot Name\", temp=False, upper_bound=1000):\n",
    "#     \"\"\"\n",
    "#     Function to plot a specified variable from a netCDF format file using matplotlib and cartopy libraries.\n",
    "#     The plot's extent is defined by the global 'extent_coords' variable which is set near the beginnning for the main script, so that is can be called on by other functions in the project. \n",
    "#     # Project extents\n",
    "#     extent_coords = {'min_lat': 36.998665, 'max_lat': 37.734463,\n",
    "#                  'min_lon': -95.964735, 'max_lon': -94.616789} \n",
    "#     An optional temperature \n",
    "#     conversion can be applied if the 'temp' argument is set to True. The function filters out values \n",
    "#     above 'upper_bound' and finds the maximum of the remaining values for each (latitude, longitude) pair.\n",
    "# \n",
    "#     Parameters:\n",
    "#     ----------\n",
    "#     mrc : cartopy.crs object\n",
    "#         The Coordinate Reference System in which to plot the data.\n",
    "#     file : str\n",
    "#         Path to the netCDF format file.\n",
    "#     dep_var : str\n",
    "#         Name of the variable from the netCDF file to be plotted.\n",
    "#     width : int, optional\n",
    "#         Width of the plot in inches. Default is 6.\n",
    "#     height : int, optional\n",
    "#         Height of the plot in inches. Default is 6.\n",
    "#     ax_title : str, optional\n",
    "#         The title for the colorbar. Default is \"Colorbar\".\n",
    "#     plt_title : str, optional\n",
    "#         The title for the plot. Default is \"Plot Name\".\n",
    "#     temp : bool, optional\n",
    "#         If True, the function assumes the provided variable is temperature in Kelvin, \n",
    "#         and will convert the temperature to Fahrenheit before plotting. Default is False.\n",
    "#     upper_bound : float, optional\n",
    "#         The maximum allowed value for the 'dep_var' variable. All values above 'upper_bound' \n",
    "#         are filtered out before the maximum of the remaining values is found. Default is 1000.\n",
    "# \n",
    "#     Returns:\n",
    "#     -------\n",
    "#     None: The function does not return any value, it displays the plot diagram.\n",
    "# \n",
    "#     Author: Gloria Hope\n",
    "#     Modified by: Jason Ehlenberger for extents functionality\n",
    "#     \"\"\"\n",
    "# \n",
    "#  # Open NetCDF dataset\n",
    "#     ds = Dataset(file)\n",
    "# \n",
    "#     # Get variable data\n",
    "#     dep = ds[dep_var][:]\n",
    "#     longs = ds['lon'][:]\n",
    "#     lats = ds['lat'][:]\n",
    "# \n",
    "#     if temp:\n",
    "#         dep = (dep - 273.15) * 9 / 5 + 32  # Convert Kelvin to Fahrenheit\n",
    "# \n",
    "#     xs, ys, zs = [], [], []\n",
    "# \n",
    "#     # filter data that have <=1000 values and get its maximum\n",
    "#     for lat in range(len(lats)):\n",
    "#         for lon in range(len(longs)):\n",
    "#             total = dep[:, lat, lon]\n",
    "#             # Apply upper_bound condition and remove NaNs\n",
    "#             total = total[total <= upper_bound]\n",
    "#             if len(total) > 0:\n",
    "#                 maximum = max(total)\n",
    "#                 xs.append(longs[lon])\n",
    "#                 ys.append(lats[lat])\n",
    "#                 zs.append(maximum)\n",
    "# \n",
    "#     fig = plt.figure(figsize=(width, height), dpi=100, facecolor=\"none\")\n",
    "#     ax = fig.add_subplot(1, 1, 1, projection=mrc)\n",
    "#     ax.stock_img()\n",
    "#     ax.coastlines()\n",
    "#     ax.add_feature(cf.STATES)\n",
    "#     ax.set_extent([extent_coords['min_lon'], extent_coords['max_lon'],\n",
    "#                extent_coords['min_lat'], extent_coords['max_lat']], crs=mrc)\n",
    "# \n",
    "#     plt.scatter(xs, ys, c=zs, cmap='rainbow', marker='s')\n",
    "#     cb = plt.colorbar()\n",
    "#     cb.ax.set_title(ax_title)\n",
    "#     plt.title(plt_title)\n",
    "# \n",
    "#     gls = ax.gridlines(draw_labels=True, color='none')\n",
    "#     gls.top_labels = False\n",
    "#     gls.right_labels = False\n",
    "# \n",
    "#     plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adbb038baee9924c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ncplotter(ccrs.Mercator(),\n",
    "#           os.path.join(src_dir, 'Gridmet_WIND/vs_2018.nc'),\n",
    "#           'wind_speed',\n",
    "#           10,\n",
    "#           6,\n",
    "#           'Maximum Daily Wind Speed',\n",
    "#           'Maximum Daily Wind Speed in 2018',\n",
    "#           False,1000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21c4c7649af7dd43",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import netCDF4 as nc\n",
    "# import numpy as np\n",
    "\n",
    "# Open the netCDF file\n",
    "file = os.path.join(src_dir, 'Gridmet_WIND/wind_v_u_igust_2014.nc')\n",
    "ds = nc.Dataset(file)\n",
    "\n",
    "# Print out all variable names in the netCDF file\n",
    "print(ds.variables.keys())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc89827ea846345d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Let's say you're interested in the variable named 'variable_of_interest'\n",
    "# # You can print out information about this variable like this:\n",
    "# print(ds.variables['time'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f5a2e3ec431da18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # You can even read the data of variable\n",
    "# data = np.array(ds.variables['time'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac9b6f9b8bc3e3c9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Now inspect the data. This code prints out the shape, min and max values of the array.\n",
    "# # Replace data with zs if you managed to load it\n",
    "# print(data.shape, np.nanmin(data), np.nanmax(data))\n",
    "# \n",
    "# # Close the Dataset\n",
    "# ds.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc6dd3e95dce026a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # import netCDF4 as nc\n",
    "# # import numpy as np\n",
    "# # import matplotlib.pyplot as plt\n",
    "# # import cartopy.crs as ccrs\n",
    "# # import matplotlib.ticker as mticker\n",
    "# # from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "# \n",
    "# \n",
    "# def ncplotws(filename):\n",
    "#     # Open netCDF file\n",
    "#     dataset = nc.Dataset(filename)\n",
    "# \n",
    "#     # Read variables\n",
    "#     lon = dataset.variables['longitude'][:]\n",
    "#     lat = dataset.variables['latitude'][:]\n",
    "#     time = dataset.variables['time'][:]\n",
    "#     u10 = dataset.variables['u10'][:]  # 10m u-component of wind\n",
    "#     v10 = dataset.variables['v10'][:]  # 10m v-component of wind\n",
    "#     i10fg = dataset.variables['i10fg'][:]  # Instantaneous 10m wind gust\n",
    "# \n",
    "#     # Close the dataset\n",
    "#     dataset.close()\n",
    "# \n",
    "#     # Compute wind speed\n",
    "#     wind_speed = np.sqrt(u10 ** 2 + v10 ** 2)\n",
    "# \n",
    "#     # Plot Wind Speed\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#     plt.contourf(lon, lat, wind_speed[0, :, :], 60, transform=ccrs.PlateCarree())\n",
    "# \n",
    "#     # Add geographic grid\n",
    "#     gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True)\n",
    "#     gl.top_labels = False\n",
    "#     gl.right_labels = False\n",
    "#     gl.xformatter = LONGITUDE_FORMATTER\n",
    "#     gl.yformatter = LATITUDE_FORMATTER\n",
    "# \n",
    "#     ax.coastlines()\n",
    "# \n",
    "#     # Add title\n",
    "#     ax.set_title('Wind Speed')\n",
    "# \n",
    "#     plt.colorbar(label='Wind Speed (m/s)')\n",
    "#     plt.show()\n",
    "# \n",
    "# # Usage:\n",
    "# # plot_wind_speed_from_netcdf('wind_v_u_igust_2014.nc')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d65c8e376d61ca18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ncplotws(os.path.join(src_dir, 'Gridmet_WIND/wind_v_u_igust_2014.nc'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56b88aabc0e35f50",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # import geopandas as gpd\n",
    "# \n",
    "# \n",
    "# def ncplotws2(filename, shapefile):\n",
    "#     # Open netCDF file\n",
    "#     dataset = nc.Dataset(filename)\n",
    "# \n",
    "#     # Read variables\n",
    "#     lon = dataset.variables['longitude'][:]\n",
    "#     lat = dataset.variables['latitude'][:]\n",
    "#     time = dataset.variables['time'][:]\n",
    "#     u10 = dataset.variables['u10'][:]  # 10m u-component of wind\n",
    "#     v10 = dataset.variables['v10'][:]  # 10m v-component of wind\n",
    "#     i10fg = dataset.variables['i10fg'][:]  # Instantaneous 10m wind gust\n",
    "# \n",
    "#     # Close the dataset\n",
    "#     dataset.close()\n",
    "# \n",
    "#     # Compute wind speed\n",
    "#     wind_speed = np.sqrt(u10 ** 2 + v10 ** 2)\n",
    "# \n",
    "#     # Plot Wind Speed\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#     plt.contourf(lon, lat, wind_speed[0, :, :], 60, transform=ccrs.PlateCarree())\n",
    "# \n",
    "#     # Add geographic grid\n",
    "#     gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, color='blue', linewidth=1)\n",
    "#     gl.top_labels = False\n",
    "#     gl.right_labels = False\n",
    "#     gl.xformatter = LONGITUDE_FORMATTER\n",
    "#     gl.yformatter = LATITUDE_FORMATTER\n",
    "# \n",
    "#     ax.coastlines()\n",
    "# \n",
    "#     # Add title\n",
    "#     ax.set_title('Wind Speed')\n",
    "# \n",
    "#     # Overlay the shapefile\n",
    "#     gdf = gpd.read_file(shapefile)\n",
    "#     gdf.plot(ax=ax, facecolor=\"none\", edgecolor='white', linewidth=2)\n",
    "# \n",
    "#     plt.colorbar(label='Wind Speed (m/s)')\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f4fa3b2bd6e7ea6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ncplotws2(os.path.join(src_dir, 'Gridmet_WIND/wind_v_u_igust_2014.nc'),sixco_fn)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40bbaae28a0f2e16",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import netCDF4 as nc\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cartopy.crs as ccrs\n",
    "# import ipywidgets as widgets\n",
    "# import geopandas as gpd\n",
    "# import matplotlib.ticker as mticker\n",
    "# from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "# from scipy.interpolate import griddata\n",
    "\n",
    "\n",
    "def ncplotws3(filename, shapefile):\n",
    "    dataset = nc.Dataset(filename)\n",
    "    lon = dataset.variables['longitude'][:]\n",
    "    lat = dataset.variables['latitude'][:]\n",
    "    time_units = dataset.variables['time'].units\n",
    "    time_cal = dataset.variables['time'].calendar\n",
    "    time = nc.num2date(dataset.variables['time'][:], time_units, time_cal)\n",
    "    u10 = dataset.variables['u10'][:]\n",
    "    v10 = dataset.variables['v10'][:]\n",
    "    i10fg = dataset.variables['i10fg'][:]\n",
    "    dataset.close()\n",
    "\n",
    "    def plot_netcdf_time(time_index):\n",
    "        wind_speed = np.sqrt(u10[time_index, :, :] ** 2 + v10[time_index, :, :] ** 2)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        plt.contourf(lon, lat, wind_speed, 60, transform=ccrs.PlateCarree())\n",
    "    \n",
    "        # Due to the possible large size of the data, we take every nth data point to keep the plot from becoming overloaded\n",
    "        n = 1\n",
    "        ax.barbs(lon[::n], lat[::n], u10[time_index, ::n, ::n], v10[time_index, ::n, ::n], length=5, color='white')\n",
    "\n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, color='blue', linewidth=1)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.xformatter = LONGITUDE_FORMATTER\n",
    "        gl.yformatter = LATITUDE_FORMATTER\n",
    "        ax.coastlines()\n",
    "        ax.set_title('Wind Speed and direction ' + str(time[time_index]))\n",
    "        gdf = gpd.read_file(shapefile)\n",
    "        gdf.plot(ax=ax, facecolor=\"none\", edgecolor='white', linewidth=2)\n",
    "\n",
    "        plt.colorbar(label='Wind Speed (m/s)')\n",
    "        plt.show()\n",
    "\n",
    "    time_slider = widgets.IntSlider(min=0, max=len(time) - 1, step=1, value=0, description='Time Index:')\n",
    "    play = widgets.Play(min=0, max=len(time) - 1, step=24, value=0, interval=1000)\n",
    "    widgets.jslink((play, 'value'), (time_slider, 'value'))\n",
    "    \n",
    "    plot_func = widgets.interactive_output(plot_netcdf_time, {'time_index': time_slider})\n",
    "    \n",
    "    display(widgets.HBox([play, time_slider]))\n",
    "    display(plot_func)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c69b4cbd54f6d4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ncplotws3(os.path.join(src_dir, 'Gridmet_WIND/wind_v_u_igust_2014.nc'),sixco_fn)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7cff4045529116b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ncplotws4(filename, boundary_shapefile, storm_shapefile, events_csv):\n",
    "    dataset = nc.Dataset(filename)\n",
    "    lon = dataset.variables['longitude'][:]\n",
    "    lat = dataset.variables['latitude'][:]\n",
    "    time_units = dataset.variables['time'].units\n",
    "    time_cal = dataset.variables['time'].calendar\n",
    "    time = nc.num2date(dataset.variables['time'][:], time_units, time_cal)\n",
    "    u10 = dataset.variables['u10'][:]\n",
    "    v10 = dataset.variables['v10'][:]\n",
    "    i10fg = dataset.variables['i10fg'][:]\n",
    "    dataset.close()\n",
    "\n",
    "    def plot_netcdf_time(time_index):\n",
    "        wind_speed = np.sqrt(u10[time_index, :, :] ** 2 + v10[time_index, :, :] ** 2)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        plt.contourf(lon, lat, wind_speed, 60, transform=ccrs.PlateCarree())\n",
    "\n",
    "        n = 1\n",
    "        ax.barbs(lon[::n], lat[::n], u10[time_index, ::n, ::n], v10[time_index, ::n, ::n], length=5, color='white')\n",
    "\n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, color='blue', linewidth=1)\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.xformatter = LONGITUDE_FORMATTER\n",
    "        gl.yformatter = LATITUDE_FORMATTER\n",
    "        ax.coastlines()\n",
    "\n",
    "        ax.set_title('Wind Speed and Direction ' + str(time[time_index]))\n",
    "\n",
    "        # Load and plot boundary shapefile\n",
    "        boundary_gdf = gpd.read_file(boundary_shapefile)\n",
    "        boundary_gdf.plot(ax=ax, facecolor=\"none\", edgecolor='white', linewidth=2.0)\n",
    "\n",
    "        # Load storm events shapefile and CSV, merge them (inner join) and plot\n",
    "        storm_gdf = gpd.read_file(storm_shapefile)\n",
    "        csv_df = pd.read_csv(events_csv, parse_dates=['BEGIN_DATE_TIME_det'])\n",
    "        merged_gdf = storm_gdf.merge(csv_df, how='inner', left_on=\"EVENT_ID\", right_on='EVENT_ID')\n",
    "\n",
    "        for x in range(len(merged_gdf)):\n",
    "            line = merged_gdf.geometry.iloc[x]\n",
    "            ax.plot(line.x, line.y, color='green', linewidth=0.8)\n",
    "            if x < 10:  # Adjust this threshold as needed\n",
    "                ax.text(line.x[0], line.y[0], ' Event ' + str(merged_gdf.EVENT_ID.iloc[x]))\n",
    "\n",
    "        plt.colorbar(label='Wind Speed (m/s)')\n",
    "        plt.show()\n",
    "\n",
    "    time_slider = widgets.IntSlider(min=0, max=len(time) - 1, step=1, value=0, description='Time Index:')\n",
    "    play = widgets.Play(min=0, max=len(time) - 1, step=24, value=0, interval=1000)\n",
    "    widgets.jslink((play, 'value'), (time_slider, 'value'))\n",
    "\n",
    "    plot_func = widgets.interactive_output(plot_netcdf_time, {'time_index': time_slider})\n",
    "\n",
    "    display(widgets.HBox([play, time_slider]))\n",
    "    display(plot_func)\n",
    "\n",
    "\n",
    "ncplotws4(os.path.join(src_dir, 'Gridmet_WIND/wind_v_u_igust_2014.nc'), 'sixco_fn', 'Data/Storm_event/StormEvents2014.shp',\n",
    "          'Data/Storm_event/StormEvents_2014.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3ac8dc36baec63e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ncplotws4(os.path.join(src_dir, 'Gridmet_WIND/wind_v_u_igust_2014.nc'), 'sixco_fn', 'Data/Storm_event/StormEvents2014.shp',\n",
    "          'Data/Storm_event/StormEvents_2014.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb6f9fc1b856776d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   EVENT_ID  EPISODE_ID  BEGIN_YEARMONTH_det  BEGIN_DAY_det  BEGIN_TIME_det  \\\n0    543659       90610               201410              9            2230   \n1    543659       90610               201410              9            2230   \n2    543659       90610               201410              9            2230   \n3    543659       90610               201410              9            2230   \n4    533649       88474               201409              5            1755   \n\n   END_YEARMONTH_det  END_DAY_det  END_TIME_det STATE_det  STATE_FIPS_det  \\\n0             201410           10          1400    KANSAS              20   \n1             201410           10          1400    KANSAS              20   \n2             201410           10          1400    KANSAS              20   \n3             201410           10          1400    KANSAS              20   \n4             201409            5          1755    KANSAS              20   \n\n   ...  DATA_SOURCE_det YEARMONTH_loc LOCATION_INDEX_loc RANGE_loc  \\\n0  ...              CSV        201410                  1      1.41   \n1  ...              CSV        201410                  2      2.94   \n2  ...              CSV        201410                  3      3.27   \n3  ...              CSV        201410                  4      2.90   \n4  ...              CSV        201409                  1      3.83   \n\n   AZIMUTH_loc LOCATION_loc LATITUDE LONGITUDE      LAT2      LON2  \n0          WNW    MOUND VLY  37.2063  -95.4444  37.12378 -95.26664  \n1          ENE    MOUND VLY  37.2102  -95.3682  37.12612 -95.22092  \n2           SE    MOUND VLY  37.1699  -95.3740  37.10194 -95.22440  \n3           SW    MOUND VLY  37.1699  -95.4568  37.10194 -95.27408  \n4          SSW     KNIVETON  37.2700  -94.7000  37.16200 -94.42000  \n\n[5 rows x 60 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EVENT_ID</th>\n      <th>EPISODE_ID</th>\n      <th>BEGIN_YEARMONTH_det</th>\n      <th>BEGIN_DAY_det</th>\n      <th>BEGIN_TIME_det</th>\n      <th>END_YEARMONTH_det</th>\n      <th>END_DAY_det</th>\n      <th>END_TIME_det</th>\n      <th>STATE_det</th>\n      <th>STATE_FIPS_det</th>\n      <th>...</th>\n      <th>DATA_SOURCE_det</th>\n      <th>YEARMONTH_loc</th>\n      <th>LOCATION_INDEX_loc</th>\n      <th>RANGE_loc</th>\n      <th>AZIMUTH_loc</th>\n      <th>LOCATION_loc</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>LAT2</th>\n      <th>LON2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>543659</td>\n      <td>90610</td>\n      <td>201410</td>\n      <td>9</td>\n      <td>2230</td>\n      <td>201410</td>\n      <td>10</td>\n      <td>1400</td>\n      <td>KANSAS</td>\n      <td>20</td>\n      <td>...</td>\n      <td>CSV</td>\n      <td>201410</td>\n      <td>1</td>\n      <td>1.41</td>\n      <td>WNW</td>\n      <td>MOUND VLY</td>\n      <td>37.2063</td>\n      <td>-95.4444</td>\n      <td>37.12378</td>\n      <td>-95.26664</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>543659</td>\n      <td>90610</td>\n      <td>201410</td>\n      <td>9</td>\n      <td>2230</td>\n      <td>201410</td>\n      <td>10</td>\n      <td>1400</td>\n      <td>KANSAS</td>\n      <td>20</td>\n      <td>...</td>\n      <td>CSV</td>\n      <td>201410</td>\n      <td>2</td>\n      <td>2.94</td>\n      <td>ENE</td>\n      <td>MOUND VLY</td>\n      <td>37.2102</td>\n      <td>-95.3682</td>\n      <td>37.12612</td>\n      <td>-95.22092</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>543659</td>\n      <td>90610</td>\n      <td>201410</td>\n      <td>9</td>\n      <td>2230</td>\n      <td>201410</td>\n      <td>10</td>\n      <td>1400</td>\n      <td>KANSAS</td>\n      <td>20</td>\n      <td>...</td>\n      <td>CSV</td>\n      <td>201410</td>\n      <td>3</td>\n      <td>3.27</td>\n      <td>SE</td>\n      <td>MOUND VLY</td>\n      <td>37.1699</td>\n      <td>-95.3740</td>\n      <td>37.10194</td>\n      <td>-95.22440</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>543659</td>\n      <td>90610</td>\n      <td>201410</td>\n      <td>9</td>\n      <td>2230</td>\n      <td>201410</td>\n      <td>10</td>\n      <td>1400</td>\n      <td>KANSAS</td>\n      <td>20</td>\n      <td>...</td>\n      <td>CSV</td>\n      <td>201410</td>\n      <td>4</td>\n      <td>2.90</td>\n      <td>SW</td>\n      <td>MOUND VLY</td>\n      <td>37.1699</td>\n      <td>-95.4568</td>\n      <td>37.10194</td>\n      <td>-95.27408</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>533649</td>\n      <td>88474</td>\n      <td>201409</td>\n      <td>5</td>\n      <td>1755</td>\n      <td>201409</td>\n      <td>5</td>\n      <td>1755</td>\n      <td>KANSAS</td>\n      <td>20</td>\n      <td>...</td>\n      <td>CSV</td>\n      <td>201409</td>\n      <td>1</td>\n      <td>3.83</td>\n      <td>SSW</td>\n      <td>KNIVETON</td>\n      <td>37.2700</td>\n      <td>-94.7000</td>\n      <td>37.16200</td>\n      <td>-94.42000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows  60 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read shapefile and relate table\n",
    "shapefile = os.path.join(src_dir,'Storm_event/StormEvents2014.shp')\n",
    "relate_table = os.path.join(src_dir, 'Storm_event/StormEvents_2014.csv')\n",
    "gdf = gpd.read_file(shapefile)\n",
    "relate_df = pd.read_csv(relate_table)\n",
    "relate_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T19:08:51.140863Z",
     "start_time": "2024-03-27T19:08:51.097933Z"
    }
   },
   "id": "92d6e20bd65a5fcc",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Column Name: EVENT_ID\n",
      "Index: 1, Column Name: EPISODE_ID\n",
      "Index: 2, Column Name: BEGIN_YEARMONTH_det\n",
      "Index: 3, Column Name: BEGIN_DAY_det\n",
      "Index: 4, Column Name: BEGIN_TIME_det\n",
      "Index: 5, Column Name: END_YEARMONTH_det\n",
      "Index: 6, Column Name: END_DAY_det\n",
      "Index: 7, Column Name: END_TIME_det\n",
      "Index: 8, Column Name: STATE_det\n",
      "Index: 9, Column Name: STATE_FIPS_det\n",
      "Index: 10, Column Name: YEAR_det\n",
      "Index: 11, Column Name: MONTH_NAME_det\n",
      "Index: 12, Column Name: EVENT_TYPE_det\n",
      "Index: 13, Column Name: CZ_TYPE_det\n",
      "Index: 14, Column Name: CZ_FIPS_det\n",
      "Index: 15, Column Name: CZ_NAME_det\n",
      "Index: 16, Column Name: WFO_det\n",
      "Index: 17, Column Name: BEGIN_DATE_TIME_det\n",
      "Index: 18, Column Name: CZ_TIMEZONE_det\n",
      "Index: 19, Column Name: END_DATE_TIME_det\n",
      "Index: 20, Column Name: INJURIES_DIRECT_det\n",
      "Index: 21, Column Name: INJURIES_INDIRECT_det\n",
      "Index: 22, Column Name: DEATHS_DIRECT_det\n",
      "Index: 23, Column Name: DEATHS_INDIRECT_det\n",
      "Index: 24, Column Name: DAMAGE_PROPERTY_det\n",
      "Index: 25, Column Name: DAMAGE_CROPS_det\n",
      "Index: 26, Column Name: SOURCE_det\n",
      "Index: 27, Column Name: MAGNITUDE_det\n",
      "Index: 28, Column Name: MAGNITUDE_TYPE_det\n",
      "Index: 29, Column Name: FLOOD_CAUSE_det\n",
      "Index: 30, Column Name: CATEGORY_det\n",
      "Index: 31, Column Name: TOR_F_SCALE_det\n",
      "Index: 32, Column Name: TOR_LENGTH_det\n",
      "Index: 33, Column Name: TOR_WIDTH_det\n",
      "Index: 34, Column Name: TOR_OTHER_WFO_det\n",
      "Index: 35, Column Name: TOR_OTHER_CZ_STATE_det\n",
      "Index: 36, Column Name: TOR_OTHER_CZ_FIPS_det\n",
      "Index: 37, Column Name: TOR_OTHER_CZ_NAME_det\n",
      "Index: 38, Column Name: BEGIN_RANGE_det\n",
      "Index: 39, Column Name: BEGIN_AZIMUTH_det\n",
      "Index: 40, Column Name: BEGIN_LOCATION_det\n",
      "Index: 41, Column Name: END_RANGE_det\n",
      "Index: 42, Column Name: END_AZIMUTH_det\n",
      "Index: 43, Column Name: END_LOCATION_det\n",
      "Index: 44, Column Name: BEGIN_LAT_det\n",
      "Index: 45, Column Name: BEGIN_LON_det\n",
      "Index: 46, Column Name: END_LAT_det\n",
      "Index: 47, Column Name: END_LON_det\n",
      "Index: 48, Column Name: EPISODE_NARRATIVE_det\n",
      "Index: 49, Column Name: EVENT_NARRATIVE_det\n",
      "Index: 50, Column Name: DATA_SOURCE_det\n",
      "Index: 51, Column Name: YEARMONTH_loc\n",
      "Index: 52, Column Name: LOCATION_INDEX_loc\n",
      "Index: 53, Column Name: RANGE_loc\n",
      "Index: 54, Column Name: AZIMUTH_loc\n",
      "Index: 55, Column Name: LOCATION_loc\n",
      "Index: 56, Column Name: LATITUDE\n",
      "Index: 57, Column Name: LONGITUDE\n",
      "Index: 58, Column Name: LAT2\n",
      "Index: 59, Column Name: LON2\n"
     ]
    }
   ],
   "source": [
    "# get column names with their index\n",
    "for i, col_name in enumerate(relate_df.columns):\n",
    "    print(f\"Index: {i}, Column Name: {col_name}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T19:08:55.114573Z",
     "start_time": "2024-03-27T19:08:55.110055Z"
    }
   },
   "id": "fd2b32bb0fcc4ef5",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Column Name: EVENT_ID\n",
      "Index: 1, Column Name: EPISODE_ID\n",
      "Index: 2, Column Name: STATE_det\n",
      "Index: 3, Column Name: STATE_FIPS_det\n",
      "Index: 4, Column Name: YEAR_det\n",
      "Index: 5, Column Name: MONTH_NAME_det\n",
      "Index: 6, Column Name: EVENT_TYPE_det\n",
      "Index: 7, Column Name: CZ_NAME_det\n",
      "Index: 8, Column Name: BEGIN_DATE_TIME_det\n",
      "Index: 9, Column Name: CZ_TIMEZONE_det\n",
      "Index: 10, Column Name: END_DATE_TIME_det\n",
      "Index: 11, Column Name: SOURCE_det\n",
      "Index: 12, Column Name: FLOOD_CAUSE_det\n",
      "Index: 13, Column Name: BEGIN_LOCATION_det\n",
      "Index: 14, Column Name: END_LOCATION_det\n",
      "Index: 15, Column Name: BEGIN_LAT_det\n",
      "Index: 16, Column Name: BEGIN_LON_det\n",
      "Index: 17, Column Name: END_LAT_det\n",
      "Index: 18, Column Name: END_LON_det\n",
      "Index: 19, Column Name: EPISODE_NARRATIVE_det\n",
      "Index: 20, Column Name: EVENT_NARRATIVE_det\n",
      "Index: 21, Column Name: LATITUDE\n",
      "Index: 22, Column Name: LONGITUDE\n",
      "Index: 23, Column Name: LAT2\n",
      "Index: 24, Column Name: LON2\n"
     ]
    }
   ],
   "source": [
    "# Drop the unwanted columns \n",
    "if len(relate_df.columns) > 25:\n",
    "    rel_table = relate_df.drop(relate_df.columns[np.r_[2:8, 13:15, 16, 20:26, 27:29, 30:40, 41:43, 50:56]], axis=1)\n",
    "else: rel_table = relate_df\n",
    "\n",
    "# get column names with their index, again\n",
    "for i, col_name in enumerate(rel_table.columns):\n",
    "    print(f\"Index: {i}, Column Name: {col_name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T19:11:38.536198Z",
     "start_time": "2024-03-27T19:11:38.530641Z"
    }
   },
   "id": "fc64cf793f5b97ae",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rel_table[\"BEGIN_DATE_TIME_det\"] = pd.to_datetime(rel_table[\"BEGIN_DATE_TIME_det\"], format=\"%d-%b-%y %H:%M:%S\")\n",
    "\n",
    "df = pd.merge(gdf, rel_table, on='EVENT_ID')\n",
    "df.head(1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f878528f82d68cf",
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# from datetime import datetime\n",
    "# \n",
    "# # Read shapefile and relate table\n",
    "# shapefile = 'Output/StormEvents2014.shp'\n",
    "# relate_table = os.path.join(src_dir, 'Storm_event/StormEvents_2014.csv')\n",
    "# gdf = gpd.read_file(shapefile)\n",
    "# relate_df = pd.read_csv(relate_table)\n",
    "# relate_df[\"BEGIN_DATE_TIME_det\"] = pd.to_datetime(relate_df[\"BEGIN_DATE_TIME_det\"], format=\"%d-%b-%y %H:%M:%S\")\n",
    "# \n",
    "# df = pd.merge(gdf, relate_df, on='EVENT_ID')\n",
    "# \n",
    "# # Checking if the merge is successful\n",
    "# # print(df.shape)\n",
    "# # print(df.head())\n",
    "# \n",
    "# # Checking if there are any records after the filtering\n",
    "# random_date = datetime.strptime(\"2014-01-01\", \"%Y-%m-%d\").date()  # Example date\n",
    "# df_time_filtered = df[df['BEGIN_DATE_TIME_det'].dt.date == random_date]\n",
    "# # print(df_time_filtered.shape)\n",
    "# # print(df_time_filtered.head())\n",
    "# print(df['BEGIN_DATE_TIME_det'].dt.date.unique())\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c25719ec654a4066"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Call the function with your netCDF file and your shapefile\n",
    "# widgets.interact(plot_slider_ws(os.path.join(src_dir, 'Gridmet_WIND/wind_v_u_igust_2014.nc'),'Output/StormEvents2014.shp')) #, os.path.join(src_dir, 'Storm_event/StormEvents_2014.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "717b45cb0515deb5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "whos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89e24e95b5e64454",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data munging steps in excel if the next function doesn't work.\n",
    "For storm event csv add to column L this '=(LEFT(J1, 2) & \".\" & MID(J1, 3, LEN(J1)-2))*1', and in column M add '=(-LEFT(K1, 2) & \".\" & MID(K1, 3, LEN(K1)-2))*1'\n",
    "Then copy down\n",
    "Copy columns L and M and paste special 'values only' in L and M\n",
    "delete comlumns J and K\n",
    "change column headers to 'LAT2' and 'LON2'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d8a43f1d5712af"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Data munging function customized for Storm Event csv's from [NOAA Storm Events (NCEI)](https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/)\n",
    "\n",
    "# def modify_csv(filename):\n",
    "#     # Load the CSV data into a pandas DataFrame\n",
    "#     df = pd.read_csv(filename)\n",
    "# \n",
    "#     # Convert 'LAT2' and 'LON2' to string, insert decimal point after second digit, and then to floats:\n",
    "#     if 'LAT2' in df.columns:\n",
    "#         df['LAT2'] = (df['LAT2'].astype(str).str.lstrip('-').apply(lambda x: x[:2] + '.' + x[2:])).astype(float)\n",
    "#     if 'LON2' in df.columns:\n",
    "#         df['LON2'] = (df['LON2'].astype(str).str.lstrip('-').apply(lambda x: '-' + x[:2] + '.' + x[2:])).astype(float)\n",
    "# \n",
    "#     \n",
    "#     # Extract year from filename\n",
    "#     match = re.search(r'_d(\\d{4})', filename)\n",
    "#     if match:\n",
    "#         year = match.group(1)\n",
    "#     else:\n",
    "#         year = 'Unknown'\n",
    "# \n",
    "#     # Construct new filename\n",
    "#     old_filename = os.path.basename(filename)\n",
    "#     \n",
    "#     # Change 'd2014_c20231116' format to '2014'\n",
    "#     year = re.search('d(\\d{4})', old_filename).group(1)\n",
    "#     \n",
    "#     # Change 'StormEvents_locations-ftp_v1.0_d2014_c20231116.csv' format to 'StormEvents_locations'\n",
    "#     new_part = old_filename.split('-')[0]\n",
    "#     \n",
    "#     # Construct new filename, change 'StormEvents_locations' format to 'StormEvents_locations_2014.csv'\n",
    "#     new_filename = os.path.join(os.path.dirname(filename), f'{new_part}_{year}.csv')\n",
    "# \n",
    "#     # Save modified DataFrame back to CSV\n",
    "#     df.to_csv(new_filename, index=False)\n",
    "#\n",
    "#\n",
    "# # Use glob.glob() to get all the files that start with 'Storm_event/StormEvents'\n",
    "# files = glob.glob(os.path.join(src_dir, 'Storm_event/StormEvents_*'))\n",
    "# \n",
    "# # Run the modify_csv function for each file using list comprehension\n",
    "# for f in files:\n",
    "#     modify_csv(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9790347a00945ebd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b1b357e7a6c0064"
  },
  {
   "cell_type": "markdown",
   "source": [
    "    event_ids_to_add = [498864, 508406, 508407, 508408, 508409, 508413, 508414, 508440, 508468, 508476, 508480, 508481, 508482, 516243, 516244, 516245, 516246, 526836, 526837, 533868, 542919, 543368, 543376, 543645, 543646, 543667, 627803, 627804, 627806, 630383, 630387, 632580, 633147, 636638, 655474, 659269, 659272, 659273, 659274, 659292, 660117, 660118, 661872, 661873, 662309, 662310, 663504, 663539, 663987, 663989, 663991, 754111, 755412, 756557, 756559, 756560, 756562, 756563, 756564, 756569, 756576, 756578, 756608, 756609, 756611, 756861, 765900, 765905, 772228, 772229, 774573, 774574, 779898, 779899, 780508, 780781, 787624, 787627, 787630, 792763]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5c2026309f31062"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def join_and_save(src_dir, year, extent_coords=None):\n",
    "    details = pd.read_csv(os.path.join(src_dir, f'Storm_event\\StormEvents_details_{year}.csv'))\n",
    "    locations = pd.read_csv(os.path.join(src_dir, f'Storm_event\\StormEvents_locations_{year}.csv')).drop(\n",
    "        columns='EPISODE_ID')\n",
    "\n",
    "    # List of Event IDs to be kept even after extent filtering\n",
    "    event_ids_to_add = [498864, 508406, 508407, 508408, 508409, 508413, 508414, 508440, 508468, 508476, 508480, 508481, 508482, 516243, 516244, 516245, 516246, 526836, 526837, 533868, 542919, 543368, 543376, 543645, 543646, 543667, 627803, 627804, 627806, 630383, 630387, 632580, 633147, 636638, 655474, 659269, 659272, 659273, 659274, 659292, 660117, 660118, 661872, 661873, 662309, 662310, 663504, 663539, 663987, 663989, 663991, 754111, 755412, 756557, 756559, 756560, 756562, 756563, 756564, 756569, 756576, 756578, 756608, 756609, 756611, 756861, 765900, 765905, 772228, 772229, 774573, 774574, 779898, 779899, 780508, 780781, 787624, 787627, 787630, 792763]\n",
    "\n",
    "    # Separate out specific records\n",
    "    details_to_add = details[details['EVENT_ID'].isin(event_ids_to_add)]\n",
    "    locations_to_add = locations[locations['EVENT_ID'].isin(event_ids_to_add)]\n",
    "\n",
    "    # Remove these specific records from details and locations before filtering\n",
    "    details = details[~details['EVENT_ID'].isin(event_ids_to_add)]\n",
    "    locations = locations[~locations['EVENT_ID'].isin(event_ids_to_add)]\n",
    "\n",
    "    if extent_coords:\n",
    "        details = filter_dataframe_on_extent(details, extent_coords, 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON')\n",
    "        locations = filter_dataframe_on_extent(locations, extent_coords, 'LATITUDE', 'LONGITUDE', 'LAT2', 'LON2')\n",
    "\n",
    "        # Append the separated records back to details and locations after filtering\n",
    "        details = pd.concat([details, details_to_add])\n",
    "        locations = pd.concat([locations, locations_to_add])\n",
    "\n",
    "    details.columns = [col + '_det' if col not in ['EVENT_ID', 'EPISODE_ID'] else col for col in details.columns]\n",
    "    locations.columns = [\n",
    "        col + '_loc' if col not in ['EVENT_ID', 'EPISODE_ID', 'LATITUDE', 'LONGITUDE', 'LAT2', 'LON2'] else col for col\n",
    "        in locations.columns]\n",
    "\n",
    "    merged_df = pd.merge(details, locations, on='EVENT_ID', how='outer')\n",
    "\n",
    "    column_order = ['EVENT_ID', 'EPISODE_ID'] + [col for col in merged_df.columns if\n",
    "                                                 col not in ['EVENT_ID', 'EPISODE_ID']]\n",
    "    merged_df = merged_df[column_order]\n",
    "\n",
    "    merged_df.to_csv(os.path.join(src_dir, f'Storm_event\\StormEvents_{year}.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21fb8e9d6768eb66"
  },
  {
   "cell_type": "markdown",
   "source": [
    "for year in [2014, 2016, 2018]:\n",
    "    join_and_save(src_dir, year, extent_coords = extent_coords)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8fb7b9c3aac5278"
  },
  {
   "cell_type": "markdown",
   "source": [
    "def convert_dataframe_to_shapefile(source_file, output_file, extent_coords):\n",
    "    \"\"\"\n",
    "    This function reads a CSV file and filters it based on latitude and longitude. \n",
    "    Then it drops NA rows from 'LATITUDE', 'LONGITUDE', 'LAT2', 'LON2' and converts the DataFrame into GeoDataFrame.\n",
    "    Finally, the output is saved into shapefile format.\n",
    "    \n",
    "    Args:\n",
    "    source_file: str: Path of the source CSV file.\n",
    "    output_file: str: Path of the output shapefile.\n",
    "    extent_coords: dict: \n",
    "        A dictionary containing the coordinates for area bounds to the filter. \n",
    "        Keys are 'min_lat', 'max_lat', 'min_lon', 'max_lon', belongs to either lon-lat pair. \n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the CSV data into a pandas DataFrame\n",
    "    df = pd.read_csv(source_file, dtype={'AZIMUTH': str, 'LOCATION': str})\n",
    "\n",
    "    # Pull out bounds for easier reference\n",
    "    min_lat, max_lat = extent_coords['min_lat'], extent_coords['max_lat']\n",
    "    min_lon, max_lon = extent_coords['min_lon'], extent_coords['max_lon']\n",
    "\n",
    "    # Filter the records that either start or end within the given extents\n",
    "    df_filtered = df[\n",
    "        (\n",
    "                (df['LATITUDE'] >= min_lat) &\n",
    "                (df['LATITUDE'] <= max_lat) &\n",
    "                (df['LONGITUDE'] >= min_lon) &\n",
    "                (df['LONGITUDE'] <= max_lon)\n",
    "        ) |\n",
    "        (\n",
    "                (df['LAT2'] >= min_lat) &\n",
    "                (df['LAT2'] <= max_lat) &\n",
    "                (df['LON2'] >= min_lon) &\n",
    "                (df['LON2'] <= max_lon)\n",
    "        )\n",
    "        ]\n",
    "\n",
    "    # Drop NA values from 'LATITUDE', 'LONGITUDE', 'LAT2', 'LON2'\n",
    "    df_filtered = df_filtered.dropna(subset=['LATITUDE', 'LONGITUDE', 'LAT2', 'LON2'])\n",
    "\n",
    "    # Create a new 'geometry' column in the DataFrame that contains LineString objects\n",
    "    df_filtered['geometry'] = df_filtered.apply(lambda row: LineString(\n",
    "        [(row['LONGITUDE'], row['LATITUDE']), (row['LON2'], row['LAT2'])]), axis=1)\n",
    "\n",
    "    # Convert the DataFrame to a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(df_filtered, geometry='geometry')\n",
    "\n",
    "    # Save the GeoDataFrame as a shapefile\n",
    "    gdf.to_file(output_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c1f43a842dfc624"
  },
  {
   "cell_type": "markdown",
   "source": [
    "source_file = os.path.join(src_dir, 'Storm_event/StormEvents2014.csv')\n",
    "output_file = 'Output/StormEvents2014.shp'\n",
    "extent_coords = {'min_lat': 36.998665, 'max_lat': 37.734463,\n",
    "                 'min_lon': -95.964735, 'max_lon': -94.616789}\n",
    "\n",
    "convert_dataframe_to_shapefile(source_file, output_file, extent_coords)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb8d82eb671fe927"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exploratory Analysis\n",
    "1) Describe the Data\n",
    "2) Trends\n",
    "3) Summary tables\n",
    "4) drop unneeded columns\n",
    "5) drop duplicates\n",
    "6) drop outliers\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "554985b5bcce07c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "windbreaks",
   "language": "python",
   "display_name": "WindBreaks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
